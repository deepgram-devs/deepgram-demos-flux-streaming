<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deepgram FLUX API Demo</title>
    <link rel="stylesheet" href="styles/deepgram-minimal.css">
  </head>
  <body>
    <div class="dg-container">
        <h1>ðŸŽ¤ Deepgram FLUX API Demo</h1>

        <div class="dg-panel">
            <h3>FLUX Configuration</h3>
            <div class="dg-input-group">
                <label for="preflightThreshold">Preflight Threshold (0.2-0.9, optional):</label>
                <input type="number" id="preflightThreshold" min="0.2" max="0.9" step="0.1"
                       placeholder="Leave empty to disable preflighting">
                <small>
                    Enable early turn detection for lower latency voice agents
                </small>
            </div>
            <div class="dg-input-group">
                <label for="eotThreshold">End-of-Turn Threshold (0.5-0.9):</label>
                <input type="number" id="eotThreshold" min="0.5" max="0.9" step="0.1" value="0.7">
                <small>
                    Confidence level required to detect end of speech turn
                </small>
            </div>
        </div>

        <div class="dg-status dg-status--disconnected" id="connectionStatus">
            Disconnected
        </div>

            <div class="dg-controls">
                <button id="connectBtn" class="btn btn--primary">Connect to FLUX</button>
                <button id="startMicBtn" class="btn btn--secondary" disabled> Start Microphone</button>
                <button id="stopStreamBtn" class="btn btn--danger" disabled>Stop</button>
            </div>

        <div class="dg-two-column-layout">
            <div class="dg-content-section">
                <h3>FLUX Events</h3>
                <div id="eventLog" class="dg-event-log"></div>
            </div>
            <div class="dg-content-section">
                <h3>Current Turn</h3>
                <div class="dg-info-grid">
                    <div class="dg-info-item">
                        <span class="dg-info-label">Turn Index</span>
                        <div class="dg-info-value" id="turnIndex">-</div>
                    </div>
                    <div class="dg-info-item">
                        <span class="dg-info-label">Current Event</span>
                        <div class="dg-info-value" id="currentEvent">-</div>
                    </div>
                    <div class="dg-info-item">
                        <span class="dg-info-label">End-of-Turn Confidence</span>
                        <div class="dg-info-value" id="eotConfidence">-</div>
                    </div>
                    <div class="dg-info-item">
                        <span class="dg-info-label">Audio Window</span>
                        <div class="dg-info-value" id="audioWindow">-</div>
                    </div>
                </div>
                <div class="dg-transcript-display" id="currentTranscript">
                    Transcript will appear here...
                </div>
            </div>
        </div>
    </div>

    <script>
        class FluxDemo {
            constructor() {
                this.ws = null;
                this.audioContext = null;
                this.mediaStream = null;
                this.processor = null;
                this.isUsingMicrophone = false;

                this.initializeElements();
                this.setupEventListeners();
            }

            initializeElements() {
                this.elements = {
                    preflightThreshold: document.getElementById('preflightThreshold'),
                    eotThreshold: document.getElementById('eotThreshold'),
                    connectionStatus: document.getElementById('connectionStatus'),
                    connectBtn: document.getElementById('connectBtn'),
                    startMicBtn: document.getElementById('startMicBtn'),
                    stopStreamBtn: document.getElementById('stopStreamBtn'),
                    eventLog: document.getElementById('eventLog'),
                    currentTranscript: document.getElementById('currentTranscript'),
                    turnIndex: document.getElementById('turnIndex'),
                    currentEvent: document.getElementById('currentEvent'),
                    eotConfidence: document.getElementById('eotConfidence'),
                    audioWindow: document.getElementById('audioWindow')
                };
            }

            setupEventListeners() {
                this.elements.connectBtn.onclick = () => this.toggleConnection();
                this.elements.startMicBtn.onclick = () => this.startMicrophone();
                this.elements.stopStreamBtn.onclick = () => this.stopAll();
            }

            toggleConnection() {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.disconnect();
                } else {
                    this.connect();
                }
            }

            connect() {
                this.updateStatus('connecting', 'Connecting...');
                this.elements.connectBtn.disabled = true;

                // Build WebSocket URL with parameters for our local proxy
                const params = new URLSearchParams({
                    model: 'flux-general-en',
                    sample_rate: '16000',
                    encoding: 'linear16',
                    eot_threshold: this.elements.eotThreshold.value || '0.7'
                });

                // Add preflight threshold if specified
                const preflightThreshold = this.elements.preflightThreshold.value;
                if (preflightThreshold) {
                    params.append('preflight_threshold', preflightThreshold);
                }

                // Connect to our local WebSocket proxy server
                const wsUrl = `ws://localhost:3001?${params.toString()}`;
                this.log(`ðŸ”— Connecting to: ${wsUrl}`);
                this.ws = new WebSocket(wsUrl);

                this.ws.onopen = () => {
                    this.log('âœ… Connected to FLUX API via proxy server');
                    this.updateStatus('connected', 'Connected to FLUX API');
                    this.elements.connectBtn.textContent = 'Disconnect';
                    this.elements.connectBtn.disabled = false;
                    this.elements.startMicBtn.disabled = false;
                };

                this.ws.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        this.log(`ðŸ“¨ Raw WebSocket message: ${event.data.substring(0, 200)}${event.data.length > 200 ? '...' : ''}`);
                        this.handleFluxMessage(data);
                    } catch (error) {
                        this.log(`âŒ Error parsing message: ${error.message}`);
                        this.log(`ðŸ“¨ Raw message: ${event.data.substring(0, 100)}`);
                    }
                };

                this.ws.onclose = (event) => {
                    this.log(`WebSocket closed: ${event.code} - ${event.reason}`);
                    this.updateStatus('disconnected', 'Disconnected');
                    this.elements.connectBtn.textContent = 'Connect to FLUX';
                    this.elements.connectBtn.disabled = false;
                    this.elements.startMicBtn.disabled = true;
                    this.elements.stopStreamBtn.disabled = true;
                    this.stopAll();
                };

                this.ws.onerror = (error) => {
                    this.log(`WebSocket error: ${error.message || 'Unknown error'}`);
                    this.updateStatus('disconnected', 'Connection error');
                    this.elements.connectBtn.disabled = false;
                };
            }

            disconnect() {
                if (this.ws) {
                    this.stopAll();
                    this.ws.close();
                    this.ws = null;
                }
            }


            async startMicrophone() {
                if (this.isUsingMicrophone) return;

                try {
                    this.log('ðŸŽ¤ Starting FLUX transcription with Linear16 PCM...');
                    this.log('âš ï¸  FLUX API requires raw PCM data, not compressed audio formats');

                    // Request microphone access with specific constraints for FLUX
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: false,  // Disable processing for cleaner PCM
                            noiseSuppression: false,
                            autoGainControl: false
                        }
                    });

                    this.log('âœ… Microphone access granted');
                    this.isUsingMicrophone = true;
                    this.elements.startMicBtn.disabled = true;
                    this.elements.stopStreamBtn.disabled = false;
                    this.mediaStream = stream;

                    // Create audio context at exactly 16kHz for FLUX
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });

                    this.log(`ðŸ”§ Audio context sample rate: ${this.audioContext.sampleRate}Hz`);

                    const source = this.audioContext.createMediaStreamSource(stream);

                    // Use 1024 samples (64ms at 16kHz) - must be power of 2 for createScriptProcessor
                    const bufferSize = 1024;
                    this.processor = this.audioContext.createScriptProcessor(bufferSize, 1, 1);

                    let chunkCount = 0;
                    let lastLogTime = 0;

                    this.processor.onaudioprocess = (event) => {
                        chunkCount++;
                        const now = Date.now();

                        // Log every 2 seconds to avoid spam
                        if (now - lastLogTime > 2000) {
                            this.log(`ðŸ”Š Audio processing: ${chunkCount} chunks processed, WebSocket: ${this.ws ? this.ws.readyState : 'null'}`);
                            lastLogTime = now;
                        }

                        if (this.isUsingMicrophone && this.ws && this.ws.readyState === WebSocket.OPEN) {
                            const inputData = event.inputBuffer.getChannelData(0);

                            // Check if we have actual audio signal
                            let hasSignal = false;
                            let maxAmplitude = 0;
                            for (let i = 0; i < inputData.length; i++) {
                                const abs = Math.abs(inputData[i]);
                                if (abs > maxAmplitude) maxAmplitude = abs;
                                if (abs > 0.001) hasSignal = true; // Threshold for detecting audio
                            }

                            // Log audio level periodically
                            if (chunkCount % 32 === 0) { // Every ~2 seconds at 64ms chunks
                                this.log(`ðŸŽµ Audio level: max=${(maxAmplitude * 100).toFixed(1)}%, signal=${hasSignal ? 'YES' : 'SILENT'}`);
                            }

                            // Convert Float32 to Int16 (Linear16 PCM format for FLUX)
                            const int16Array = new Int16Array(inputData.length);
                            for (let i = 0; i < inputData.length; i++) {
                                // Clamp and convert to 16-bit signed integer
                                const clampedValue = Math.max(-1, Math.min(1, inputData[i]));
                                int16Array[i] = Math.round(clampedValue * 32767);
                            }

                            // Log first few successful sends
                            if (chunkCount <= 5) {
                                this.log(`ðŸ“¤ Sending chunk ${chunkCount}: ${int16Array.length} samples, ${int16Array.buffer.byteLength} bytes`);
                            }

                            // Send Linear16 PCM data to FLUX API
                            this.ws.send(int16Array.buffer);
                        } else {
                            if (chunkCount <= 3) {
                                this.log(`âŒ Cannot send audio: mic=${this.isUsingMicrophone}, ws=${this.ws ? 'exists' : 'null'}, readyState=${this.ws ? this.ws.readyState : 'n/a'}`);
                            }
                        }
                    };

                    source.connect(this.processor);
                    this.processor.connect(this.audioContext.destination);

                    this.log('ðŸŽ¤ Linear16 PCM streaming started - speak now!');
                    this.log(`ðŸ“Š Sending ${bufferSize} samples (${(bufferSize/16000*1000).toFixed(0)}ms) per chunk`);

                } catch (error) {
                    this.log(`âŒ Microphone error: ${error.message}`);
                    this.isUsingMicrophone = false;
                    this.elements.startMicBtn.disabled = false;
                    this.elements.stopStreamBtn.disabled = true;
                }
            }

            stopAll() {
                // Stop microphone
                if (this.isUsingMicrophone) {
                    this.log('ðŸŽ¤ Stopping microphone');
                    this.isUsingMicrophone = false;

                    if (this.processor) {
                        this.processor.disconnect();
                        this.processor = null;
                    }

                    if (this.audioContext && this.audioContext.state !== 'closed') {
                        this.audioContext.close();
                        this.audioContext = null;
                    }

                    if (this.mediaStream) {
                        this.mediaStream.getTracks().forEach(track => track.stop());
                        this.mediaStream = null;
                    }
                }

                // Reset button states
                this.elements.startMicBtn.disabled = false;
                this.elements.stopStreamBtn.disabled = true;
            }

            // Backward compatibility
            stopAudioStream() {
                this.stopAll();
            }

            handleFluxMessage(data) {
                this.log(`Received: ${JSON.stringify(data, null, 2)}`);

                // Handle TurnInfo messages (FLUX API responses)
                if (data.type === 'TurnInfo') {
                    this.updateTurnInfo(data);

                    switch(data.event) {
                        case 'StartOfTurn':
                            this.log('ðŸŸ¢ User started speaking');
                            break;
                        case 'Preflight':
                            this.log('ðŸŸ¡ Preflight - medium confidence turn end');
                            break;
                        case 'SpeechResumed':
                            this.log('ðŸ”„ Speech resumed after preflight');
                            break;
                        case 'EndOfTurn':
                            this.log('ðŸ”´ End of turn - high confidence');
                            break;
                        case 'Update':
                            this.log('ðŸ“ Transcript update');
                            break;
                    }
        } else {
                    // Log other message types for debugging
                    this.log(`ðŸ“¨ Message type: ${data.type || 'unknown'}`);
                }
            }

            updateTurnInfo(data) {
                this.elements.turnIndex.textContent = data.turn_index || '-';
                this.elements.currentEvent.textContent = data.event || '-';
                this.elements.eotConfidence.textContent =
                    data.end_of_turn_confidence ? data.end_of_turn_confidence.toFixed(2) : '-';
                this.elements.audioWindow.textContent =
                    data.audio_window_start !== undefined && data.audio_window_end !== undefined
                        ? `${data.audio_window_start.toFixed(1)}s - ${data.audio_window_end.toFixed(1)}s`
                        : '-';
                this.elements.currentTranscript.textContent = data.transcript || 'Waiting for speech...';
            }

            updateStatus(type, message) {
                this.elements.connectionStatus.className = `dg-status dg-status--${type}`;
                this.elements.connectionStatus.textContent = message;
            }

            log(message) {
                const timestamp = new Date().toLocaleTimeString();
                const logMessage = `[${timestamp}] ${message}\n`;
                this.elements.eventLog.textContent += logMessage;
                this.elements.eventLog.scrollTop = this.elements.eventLog.scrollHeight;
            }
        }

        // Initialize the demo when page loads
        window.addEventListener('DOMContentLoaded', () => {
            new FluxDemo();
        });
    </script>
  </body>
</html>